{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83e1ec3b-54c8-4c3b-a1b4-0114de6646d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Названия столбцов:\n",
      "['id', 'Gender', 'Age', 'Driving_License', 'Region_Code', 'Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage', 'Annual_Premium', 'Policy_Sales_Channel', 'Vintage', 'Response']\n",
      "\n",
      "Первые 2 строк данных:\n",
      "   id Gender  Age  Driving_License  Region_Code  Previously_Insured  \\\n",
      "0   0   Male   21                1         35.0                   0   \n",
      "1   1   Male   43                1         28.0                   0   \n",
      "\n",
      "  Vehicle_Age Vehicle_Damage  Annual_Premium  Policy_Sales_Channel  Vintage  \\\n",
      "0    1-2 Year            Yes         65101.0                 124.0      187   \n",
      "1   > 2 Years            Yes         58911.0                  26.0      288   \n",
      "\n",
      "   Response  \n",
      "0         0  \n",
      "1         1  \n",
      "Строчек удалено:  92550\n",
      "4907451\n",
      "5000001\n",
      "Response\n",
      "0    4306727\n",
      "1     600724\n",
      "Name: count, dtype: int64\n",
      "Response\n",
      "0    600724\n",
      "1    600724\n",
      "Name: count, dtype: int64\n",
      "Time:  4.631528854370117  sec or  0.07719214757283528 min\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.68      0.80   5705019\n",
      "           1       0.28      0.90      0.43    799778\n",
      "\n",
      "    accuracy                           0.71   6504797\n",
      "   macro avg       0.63      0.79      0.62   6504797\n",
      "weighted avg       0.89      0.71      0.76   6504797\n",
      "\n",
      "Модель сохранена в файл: bayes_model.pkl\n",
      "Модель сохранена в файл: bayes_model.pkl\n",
      "Модель сохранена в файл: bayes_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.utils import resample\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "#Функция для перевода строки новых ненормализованных данных в строку нормализованных\n",
    "# features здесь это только числовые параметры, в том же порядке в котором они записаны в scaler (а значит в массив \"numeric_features\")\n",
    "def new_scaler(features, scale, mean):\n",
    "    for i in range(len(features)):\n",
    "        features[i] = (features[i] - mean[i])/ scale[i]\n",
    "    return features\n",
    "\n",
    "#Функция для перевода строки нормализованных данных в первоночальный вид\n",
    "def scaled_to_normal(features, scale, mean):\n",
    "    for i in range(len(features)):\n",
    "        features[i] = features[i] * scale[i] + mean[i]\n",
    "    return features\n",
    "\n",
    "#Чтение данных\n",
    "\n",
    "data = pd.read_csv('train_short.csv')\n",
    "# Показать названия всех столбцов\n",
    "print(\"\\nНазвания столбцов:\")\n",
    "print(data.columns.tolist())\n",
    "\n",
    "# Показать первые несколько строк\n",
    "print(\"\\nПервые 2 строк данных:\")\n",
    "print(data.head(2))\n",
    "\n",
    "#data = data.head(1000)\n",
    "\n",
    "# Удаляем строки с пропущенными значениями (их нет)\n",
    "data = data.dropna()\n",
    "\n",
    "dataT = pd.read_csv('test_short.csv')\n",
    "dataT = dataT.dropna()\n",
    "\n",
    "\n",
    "#Оставляем только нужные столбцы\n",
    "#columns_to_keep = ['Response', 'Gender', 'Age', 'Driving_License', 'Region_Code', 'Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage', 'Annual_Premium', 'Policy_Sales_Channel', 'Vintage']\n",
    "columns_to_keep = ['Response', 'Gender', 'Age', 'Driving_License', 'Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage', 'Annual_Premium', 'Policy_Sales_Channel']\n",
    "data = data[columns_to_keep]\n",
    "dataT = dataT[columns_to_keep]\n",
    "\n",
    "# One-hot кодирование категориальных признаков\n",
    "categorical_features = ['Gender', 'Vehicle_Age', 'Vehicle_Damage', 'Driving_License', 'Previously_Insured']\n",
    "data = pd.get_dummies(data, columns=categorical_features, drop_first=True)\n",
    "dataT = pd.get_dummies(dataT, columns=categorical_features, drop_first=True)\n",
    "\n",
    "\n",
    "length = len(data)\n",
    "\n",
    "# Нормализация числовых признаков\n",
    "#numeric_features = [\"Age\", 'Region_Code', 'Annual_Premium', 'Policy_Sales_Channel', 'Vintage']\n",
    "numeric_features = [\"Age\", 'Annual_Premium', 'Policy_Sales_Channel']\n",
    "scaler = StandardScaler()\n",
    "data[numeric_features] = scaler.fit_transform(data[numeric_features])\n",
    "#print(data.head(2))\n",
    "\n",
    "dataT[numeric_features] = scaler.transform(dataT[numeric_features])\n",
    "\n",
    "#Функция для удаления выбросов. Проверяем только численные значения\n",
    "def remove_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    #Можно тут поиграться с коэффициентом на который умножается\n",
    "    lower_bound = Q1 - 1.6 * IQR\n",
    "    upper_bound = Q3 + 1.6 * IQR\n",
    "    \n",
    "    return df[(df[column] >= lower_bound) & \n",
    "             (df[column] <= upper_bound)]\n",
    "\n",
    "data_clean = data\n",
    "#Удаление выбросов\n",
    "for col in data_clean.select_dtypes(include=['float64']).columns:\n",
    "    data_clean = remove_outliers_iqr(data_clean, col)\n",
    "\n",
    "print(\"Строчек удалено: \", len(data) - len(data_clean))\n",
    "print(len(data_clean))\n",
    "print(len(data))\n",
    "\n",
    "data = data_clean\n",
    "\n",
    "print(data.Response.value_counts())\n",
    "\n",
    "# Разделение данных\n",
    "df_majority = data[data['Response'] == 0]  # Мажоритарный класс (0)\n",
    "df_minority = data[data['Response'] == 1]  # Миноритарный класс (1)\n",
    "\n",
    "# Определяем, сколько строк оставить в классе 0 (в 2 раза больше, чем класс 1)\n",
    "n_samples = 1 * len(df_minority)  # 2:1 соотношение\n",
    "\n",
    "# Случайно выбираем подмножество\n",
    "df_majority_downsampled = resample(\n",
    "    df_majority,\n",
    "    replace=False,      # Без повторяющихся строк\n",
    "    n_samples=n_samples,\n",
    "    random_state=42     # Для воспроизводимости\n",
    ")\n",
    "\n",
    "# Объединяем с миноритарным классом\n",
    "data = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "# Проверяем соотношение\n",
    "print(data['Response'].value_counts())\n",
    "\n",
    "\n",
    "\n",
    "# Разделение на признаки (X) и целевую переменную (y)\n",
    "X_train = data.drop('Response', axis=1)\n",
    "y_train = data['Response']\n",
    "\n",
    "X_test = dataT.drop('Response', axis=1)\n",
    "y_test = dataT['Response']\n",
    "\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки. Только для проверки PCA, потом надо заменить на кросс-валидацию\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "n = 6\n",
    "# Создаем объект PCA с n компонентами\n",
    "pca = PCA(n_components=n)\n",
    "\n",
    "# Применяем PCA к данным\n",
    "pca_data = pca.fit_transform(X_train)\n",
    "\n",
    "# Создаем DataFrame с результатами\n",
    "pca_df = pd.DataFrame(\n",
    "    pca_data,\n",
    "    columns=[f'Фактор_{i+1}' for i in range(n)]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "# Naive Bayes\n",
    "\n",
    "# parameters to provide\n",
    "model_filename  = f\"bayes_model.pkl\"\n",
    "\n",
    "# run model, with timing\n",
    "t_start = time.time()\n",
    "test_model = GaussianNB()\n",
    "test_model.fit(X_train, y_train)\n",
    "y_pred = test_model.predict(X_test)\n",
    "t_finish = time.time()\n",
    "dt = t_finish - t_start\n",
    "dt2 = dt / 60.\n",
    "print(\"Time: \",  dt, \" sec or \", dt2, \"min\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "# Сохранение модели в файл\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(test_model, file)\n",
    "print(f\"Модель сохранена в файл: {model_filename}\")\n",
    "\n",
    "with open(\"pca.pkl\", 'wb') as file:\n",
    "    pickle.dump(pca, file)\n",
    "print(f\"Модель сохранена в файл: {model_filename}\")\n",
    "\n",
    "with open(\"scaler.pkl\", 'wb') as file:\n",
    "    pickle.dump(scaler, file)\n",
    "print(f\"Модель сохранена в файл: {model_filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90416e94-9e67-4abb-8bfa-7fb2d1bbc31d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
