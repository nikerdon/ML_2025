{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b06ccdfe-ea70-4f14-9cb1-76ae726fba84",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "392870e4-59d0-418b-b830-c8b718e629e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numerics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Python\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "#Machine Learning\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbd93ee-7eb5-4747-ae5a-65da507e4d8f",
   "metadata": {},
   "source": [
    "# Load Datasets and Models\n",
    "(Be careful of the sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fcd55df-e7e0-4041-a1ec-f59ce2aea555",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = pd.read_pickle('X_train_phy.pkl') # train with features close to those \n",
    "with open('X_train_pca.pkl', 'rb') as f:\n",
    "    X_train = pickle.load(f) # train with principle components of dataset\n",
    "y_train = pd.read_pickle('y_train.pkl')\n",
    "\n",
    "#X_test = pd.read_pickle('X_test_phy.pkl')\n",
    "with open('X_test_pca.pkl', 'rb') as f:\n",
    "    X_test = pickle.load(f) # train with principle components of dataset\n",
    "y_test = pd.read_pickle('y_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7447db44-0092-4626-88be-1208f9056ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_model_file(filename = 'rf_f1.pkl'):\n",
    "    with open(filename, 'rb') as f:\n",
    "        model=pickle.load(f)\n",
    "    #print(f\"model загрука в файл: {filename}\")\n",
    "    print(\"Load model: \", filename)\n",
    "    print(model) # this is how to figure out what object is stored here\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54af0016-3048-4087-944b-6be9cc369077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load any number of models into a list\n",
    "model = []\n",
    "#model.append(read_model_file('tree_model.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76cabe3b-cfad-4ab8-8d45-440d12eb7308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model:  rf_f1.pkl\n",
      "GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=8,\n",
      "             param_grid={'max_depth': [5, 10, 15],\n",
      "                         'min_samples_split': [100, 1000, 10000],\n",
      "                         'n_estimators': [10, 50, 100]},\n",
      "             scoring='f1')\n",
      "Load model:  tree_model_acc_10_50.pkl\n",
      "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
      "             param_grid={'max_depth': [5, 10],\n",
      "                         'min_samples_split': [10, 20, 50, 200]},\n",
      "             scoring='balanced_accuracy')\n",
      "Load model:  tree_model_pre_10_200.pkl\n",
      "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
      "             param_grid={'max_depth': [5, 10],\n",
      "                         'min_samples_split': [10, 20, 50, 200]},\n",
      "             scoring='precision')\n",
      "Load model:  tree1_model.pkl\n",
      "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=42),\n",
      "             param_grid={'max_depth': [3, 5, 10],\n",
      "                         'min_samples_split': [5, 10, 15]},\n",
      "             scoring='f1')\n",
      "Load model:  tree2_model.pkl\n",
      "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
      "             param_grid={'max_depth': [3, 5, 10],\n",
      "                         'min_samples_split': [5, 10, 15, 20]},\n",
      "             scoring='f1')\n",
      "Load model:  tree3_model.pkl\n",
      "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
      "             param_grid={'max_depth': [3, 5, 10, 20],\n",
      "                         'min_samples_split': [50, 200, 500, 2000, 5000,\n",
      "                                               20000]},\n",
      "             scoring='f1')\n",
      "Load model:  tree5_model.pkl\n",
      "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
      "             param_grid={'max_depth': [5, 10, 15],\n",
      "                         'min_samples_split': [20, 50, 200, 1000, 10000]},\n",
      "             scoring='f1')\n"
     ]
    }
   ],
   "source": [
    "model.append(read_model_file('rf_f1.pkl'))\n",
    "model.append(read_model_file('tree_model_acc_10_50.pkl'))\n",
    "model.append(read_model_file('tree_model_pre_10_200.pkl'))\n",
    "model.append(read_model_file('tree1_model.pkl'))\n",
    "model.append(read_model_file('tree2_model.pkl'))\n",
    "model.append(read_model_file('tree3_model.pkl'))\n",
    "model.append(read_model_file('tree5_model.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e45aaa-7c4b-4fcd-8c9f-dbfdbb156c92",
   "metadata": {},
   "source": [
    "# Find models\n",
    "\n",
    "score:\n",
    "f1 seems like the best option. It is a standard measure which works on binary classifiers with uneven class sizes. Trying something better would require much more time and energy.\n",
    "\n",
    "classifiers:\n",
    " -- I currently have trees on the PCA input, and am running such random forest. I believe that we should try the trees, but without PCA. We need to decide on minimum sample size and max depth. With such a large dataset, the minimum sample size should be large.\n",
    "\n",
    " -- kNN seems worthless in our case. It is not very useful for large datasets, so we need to have a reason to believe it is useful, and a means to shrink the dataset (like averaging nearby points).\n",
    "\n",
    " -- Naive Bayes would be good to run on the output of PCA. In this case, PCA removes the correlation, making it very useful, while the physical relevance of the features is not actually helpful.\n",
    "\n",
    " -- SVM seems to have a problem with the large sample size. I would like to run it, if possible, with a non-linear kernel, but I need to figure out the runtime issue. I would consider this an \"if we have time\" option -- analyze everything without it.\n",
    "https://scikit-learn.org/stable/modules/svm.html#tips-on-practical-use\n",
    "\n",
    " -- We could try some other ensemble model version, if someone is creative enough to think of one. Splitting the data and averaging the results is easy enough -- just don't use the same sample too many times (1 time is prefered). These ensemble versions could enable us to take advantage of the large number of samples, rather than causing them to slow down the evaluation. \n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html#sklearn.ensemble.BaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e364af",
   "metadata": {},
   "source": [
    "Decision tree doesn't work well. SVM doesn't work at all? Could try letting the tree go deep. Or perhaps we should reorder the categorical Policy_Sales_Channel based on response probability. There is no reason to assume that the order as presented means anything. Categorical Naive Bayes should work well for our data (although causes problems for interpolation or extrapolation), given the low number of potential inputs and large number of datapoints for statistical analysis. Better solutions exist (like splitting the features, averaging clusters for k-NN, ...), but I don't want to do anything too complicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e851273-3363-417f-b24b-3eccfdbf2808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "\n",
    "# parameters to provide\n",
    "tree_param_grid = {'max_depth': [3, 5, 10], 'min_samples_split': [5, 10, 15]}\n",
    "scoring         = 'f1'\n",
    "model_filename  = f\"tree_{scoring}_{tree_param_grid['max_depth'][-1]}_{tree_param_grid['min_sample_size'][0]}.pkl\"\n",
    "n_jobs          = 1      # put number of processors here\n",
    "cv              = 5\n",
    "\n",
    "# run model, with timing\n",
    "t_start = time.time()\n",
    "test_model = GridSearchCV(DecisionTreeClassifier(), tree_param_grid, scoring = scoring, n_jobs = n_jobs, cv=cv)\n",
    "test_model.fit(X_train, y_train)\n",
    "t_finish = time.time()\n",
    "dt = t_finish - t_start\n",
    "dt2 = dt / 60.\n",
    "print(\"Decision Tree Best Params:\", test_model.best_params_)\n",
    "print(\"Time: \",  dt, \" sec or \", dt2, \"min\")\n",
    "\n",
    "# Сохранение модели в файл\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(test_model, file)\n",
    "print(f\"Модель сохранена в файл: {model_filename}\")\n",
    "\n",
    "#save model in the model array\n",
    "#model.append(test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9948495b-f960-44a0-b148-0c28dde84e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "# parameters to provide\n",
    "rf_param_grid   = {'n_estimators': [10, 50, 100, 200], 'max_depth': [5, 10, 15], 'min_samples_split': [3, 5, 10]}\n",
    "scoring         = 'f1'\n",
    "model_filename  = f\"forest_{scoring}_{rf_param_grid['max_depth'][-1]}_{rf_param_grid['min_sample_size'][0]}.pkl\"\n",
    "n_jobs          = 8      # put number of processors here\n",
    "cv              = 5\n",
    "\n",
    "# run model, with timing\n",
    "t_start = time.time()\n",
    "test_model = GridSearchCV(RandomForestClassifier(), rf_param_grid, scoring = scoring, n_jobs = n_jobs, cv=cv)\n",
    "test_model.fit(X_train, y_train)\n",
    "t_finish = time.time()\n",
    "dt = t_finish - t_start\n",
    "dt2 = dt / 60.\n",
    "print(\"Random Forest Best Params:\", test_model.best_params_)\n",
    "print(\"Time: \",  dt, \" sec or \", dt2, \"min\")\n",
    "\n",
    "# Сохранение модели в файл\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(test_model, file)\n",
    "print(f\"Модель сохранена в файл: {model_filename}\")\n",
    "\n",
    "#save model in the model array\n",
    "#model.append(test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9892e6-ca80-438c-a09a-6e53a572436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine (SVM)\n",
    "# Don't run -- requires too much time\n",
    "# Maybe C is incorrect. ... \n",
    "\n",
    "# parameters to provide\n",
    "svm_param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "scoring         = 'f1'\n",
    "model_filename  = f\"svm_model_{scoring}.pkl\"\n",
    "n_jobs          = 1      # put number of processors here\n",
    "cv              = 5\n",
    "\n",
    "# run model, with timing\n",
    "t_start = time.time()\n",
    "test_model = GridSearchCV(SVC(), svm_param_grid, scoring = scoring, n_jobs = n_jobs, cv=cv)\n",
    "test_model.fit(X_train, y_train)\n",
    "t_finish = time.time()\n",
    "dt = t_finish - t_start\n",
    "dt2 = dt / 60.\n",
    "print(\"SVC Best Params:\", test_model.best_params_)\n",
    "print(\"Time: \",  dt, \" sec or \", dt2, \"min\")\n",
    "\n",
    "# Сохранение модели в файл\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(test_model, file)\n",
    "print(f\"Модель сохранена в файл: {model_filename}\")\n",
    "\n",
    "#save model in the model array\n",
    "#model.append(test_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2868664-c071-4613-b841-8871e508a573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "# parameters to provide\n",
    "model_filename  = f\"bayes_model.pkl\"\n",
    "\n",
    "# run model, with timing\n",
    "t_start = time.time()\n",
    "test_model = GaussianNB()\n",
    "test_model.fit(X_train, y_train)\n",
    "t_finish = time.time()\n",
    "dt = t_finish - t_start\n",
    "dt2 = dt / 60.\n",
    "print(\"Time: \",  dt, \" sec or \", dt2, \"min\")\n",
    "\n",
    "# Сохранение модели в файл\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(test_model, file)\n",
    "print(f\"Модель сохранена в файл: {model_filename}\")\n",
    "\n",
    "#save model in the model array\n",
    "#model.append(test_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee4ef66",
   "metadata": {},
   "source": [
    "Our data consists of a finite number of categories for each numerical point, for which order may not mean anything. CategoricalNB may work well for the original dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44108af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.CategoricalNB.html#sklearn.naive_bayes.CategoricalNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9d7fbc-de3b-4fc0-84a8-5281289a1725",
   "metadata": {},
   "source": [
    "# Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4347d95b-d1d4-483a-a498-b8f14c31ff6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93   5705019\n",
      "           1       0.51      0.01      0.02    799778\n",
      "\n",
      "    accuracy                           0.88   6504797\n",
      "   macro avg       0.69      0.50      0.48   6504797\n",
      "weighted avg       0.83      0.88      0.82   6504797\n",
      "\n",
      "[[5696201    8818]\n",
      " [ 790735    9043]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93   5705019\n",
      "           1       0.32      0.00      0.00    799778\n",
      "\n",
      "    accuracy                           0.88   6504797\n",
      "   macro avg       0.60      0.50      0.47   6504797\n",
      "weighted avg       0.81      0.88      0.82   6504797\n",
      "\n",
      "[[5703304    1715]\n",
      " [ 798956     822]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93   5705019\n",
      "           1       0.36      0.00      0.00    799778\n",
      "\n",
      "    accuracy                           0.88   6504797\n",
      "   macro avg       0.62      0.50      0.47   6504797\n",
      "weighted avg       0.81      0.88      0.82   6504797\n",
      "\n",
      "[[5703769    1250]\n",
      " [ 799076     702]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    y_pred = model[i].predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3427288-537d-432b-be53-2c9cc487eee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93   5705019\n",
      "           1       0.30      0.00      0.00    799778\n",
      "\n",
      "    accuracy                           0.88   6504797\n",
      "   macro avg       0.59      0.50      0.47   6504797\n",
      "weighted avg       0.81      0.88      0.82   6504797\n",
      "\n",
      "[[5702665    2354]\n",
      " [ 798771    1007]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model[4].predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5810a93c-2bd3-4c5b-b1e8-7b50e45eba2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93   5705019\n",
      "           1       0.39      0.04      0.07    799778\n",
      "\n",
      "    accuracy                           0.87   6504797\n",
      "   macro avg       0.64      0.52      0.50   6504797\n",
      "weighted avg       0.82      0.87      0.83   6504797\n",
      "\n",
      "[[5656178   48841]\n",
      " [ 767902   31876]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93   5705019\n",
      "           1       0.42      0.02      0.04    799778\n",
      "\n",
      "    accuracy                           0.88   6504797\n",
      "   macro avg       0.65      0.51      0.49   6504797\n",
      "weighted avg       0.82      0.88      0.82   6504797\n",
      "\n",
      "[[5679890   25129]\n",
      " [ 781857   17921]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model[5].predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "y_pred = model[6].predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb71f2ac-f34e-48a0-b5e5-7ced8c81a755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
      "             param_grid={'max_depth': [3, 5, 10, 20],\n",
      "                         'min_samples_split': [50, 200, 500, 2000, 5000,\n",
      "                                               20000]},\n",
      "             scoring='f1')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93   5705019\n",
      "           1       0.39      0.04      0.07    799778\n",
      "\n",
      "    accuracy                           0.87   6504797\n",
      "   macro avg       0.64      0.52      0.50   6504797\n",
      "weighted avg       0.82      0.87      0.83   6504797\n",
      "\n",
      "[[5656178   48841]\n",
      " [ 767902   31876]]\n"
     ]
    }
   ],
   "source": [
    "print(model[5])\n",
    "y_pred = model[5].predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd85ee8a-4275-4df6-90c8-739fac7f0d43",
   "metadata": {},
   "source": [
    "The best one has a maximum depth of 20. Obviously I was wrong in wanting to limit the depth of the tree, as even on the test data it is getting better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
