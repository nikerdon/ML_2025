{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция для перевода строки новых ненормализованных данных в строку нормализованных\n",
    "# features здесь это только числовые параметры, в том же порядке в котором они записаны в scaler (а значит в массив \"numeric_features\")\n",
    "def new_scaler(features, scale, mean):\n",
    "    for i in range(len(features)):\n",
    "        features[i] = (features[i] - mean[i])/ scale[i]\n",
    "    return features\n",
    "\n",
    "#Функция для перевода строки нормализованных данных в первоночальный вид\n",
    "def scaled_to_normal(features, scale, mean):\n",
    "    for i in range(len(features)):\n",
    "        features[i] = features[i] * scale[i] + mean[i]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Названия столбцов:\n",
      "['id', 'Gender', 'Age', 'Driving_License', 'Region_Code', 'Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage', 'Annual_Premium', 'Policy_Sales_Channel', 'Vintage', 'Response']\n",
      "\n",
      "Первые 2 строк данных:\n",
      "   id Gender  Age  Driving_License  Region_Code  Previously_Insured  \\\n",
      "0   0   Male   21                1         35.0                   0   \n",
      "1   1   Male   43                1         28.0                   0   \n",
      "\n",
      "  Vehicle_Age Vehicle_Damage  Annual_Premium  Policy_Sales_Channel  Vintage  \\\n",
      "0    1-2 Year            Yes         65101.0                 124.0      187   \n",
      "1   > 2 Years            Yes         58911.0                  26.0      288   \n",
      "\n",
      "   Response  \n",
      "0         0  \n",
      "1         1  \n"
     ]
    }
   ],
   "source": [
    "#Чтение данных\n",
    "\n",
    "data = pd.read_csv('train_short.csv')\n",
    "# Показать названия всех столбцов\n",
    "print(\"\\nНазвания столбцов:\")\n",
    "print(data.columns.tolist())\n",
    "\n",
    "# Показать первые несколько строк\n",
    "print(\"\\nПервые 2 строк данных:\")\n",
    "print(data.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000001 entries, 0 to 5000000\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Dtype  \n",
      "---  ------                -----  \n",
      " 0   id                    int64  \n",
      " 1   Gender                object \n",
      " 2   Age                   int64  \n",
      " 3   Driving_License       int64  \n",
      " 4   Region_Code           float64\n",
      " 5   Previously_Insured    int64  \n",
      " 6   Vehicle_Age           object \n",
      " 7   Vehicle_Damage        object \n",
      " 8   Annual_Premium        float64\n",
      " 9   Policy_Sales_Channel  float64\n",
      " 10  Vintage               int64  \n",
      " 11  Response              int64  \n",
      "dtypes: float64(3), int64(6), object(3)\n",
      "memory usage: 457.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Удаляем строки с пропущенными значениями (их нет)\n",
    "data = data.dropna()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Оставляем только нужные столбцы\n",
    "#columns_to_keep = ['Response', 'Gender', 'Age', 'Driving_License', 'Region_Code', 'Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage', 'Annual_Premium', 'Policy_Sales_Channel', 'Vintage']\n",
    "columns_to_keep = ['Response', 'Gender', 'Age', 'Driving_License', 'Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage', 'Annual_Premium']\n",
    "#columns_to_keep = ['Response', 'Gender', 'Age', 'Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage', 'Policy_Sales_Channel']\n",
    "data = data[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testD = pd.read_csv('test_short.csv')\n",
    "#testD = testD[columns_to_keep]\n",
    "#testD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot кодирование категориальных признаков\n",
    "categorical_features = ['Gender', 'Vehicle_Age', 'Vehicle_Damage', 'Driving_License', 'Previously_Insured']\n",
    "#categorical_features = ['Gender', 'Vehicle_Age', 'Vehicle_Damage', 'Previously_Insured']\n",
    "\n",
    "data = pd.get_dummies(data, columns=categorical_features, drop_first=True)\n",
    "\n",
    "length = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testD = pd.get_dummies(testD, columns=categorical_features, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализация числовых признаков\n",
    "#numeric_features = [\"Age\", 'Region_Code', 'Annual_Premium', 'Policy_Sales_Channel', 'Vintage']\n",
    "numeric_features = [\"Age\", 'Annual_Premium']\n",
    "#numeric_features = [\"Age\", 'Policy_Sales_Channel']\n",
    "scaler = StandardScaler()\n",
    "data[numeric_features] = scaler.fit_transform(data[numeric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testD[numeric_features] = scaler.transform(testD[numeric_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def remove_outliers_iqr(df, column):\\n    Q1 = df[column].quantile(0.25)\\n    Q3 = df[column].quantile(0.75)\\n    IQR = Q3 - Q1\\n    \\n    #Можно тут поиграться с коэффициентом на который умножается\\n    lower_bound = Q1 - 1.6 * IQR\\n    upper_bound = Q3 + 1.6 * IQR\\n    \\n    return df[(df[column] >= lower_bound) & \\n             (df[column] <= upper_bound)]\\n\\ndata_clean = data\\n#Удаление выбросов\\nfor col in data_clean.select_dtypes(include=[\\'float64\\']).columns:\\n    data_clean = remove_outliers_iqr(data_clean, col)\\n\\nprint(\"Строчек удалено: \", len(data) - len(data_clean))\\nprint(len(data_clean))\\nprint(len(data))'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Функция для удаления выбросов. Проверяем только численные значения\n",
    "'''def remove_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    #Можно тут поиграться с коэффициентом на который умножается\n",
    "    lower_bound = Q1 - 1.6 * IQR\n",
    "    upper_bound = Q3 + 1.6 * IQR\n",
    "    \n",
    "    return df[(df[column] >= lower_bound) & \n",
    "             (df[column] <= upper_bound)]\n",
    "\n",
    "data_clean = data\n",
    "#Удаление выбросов\n",
    "for col in data_clean.select_dtypes(include=['float64']).columns:\n",
    "    data_clean = remove_outliers_iqr(data_clean, col)\n",
    "\n",
    "print(\"Строчек удалено: \", len(data) - len(data_clean))\n",
    "print(len(data_clean))\n",
    "print(len(data))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data = data_clean'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''data = data_clean'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response\n",
       "0    4384720\n",
       "1     615281\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Данные несбалансированные\n",
    "data.Response.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response</th>\n",
       "      <th>Age</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Vehicle_Age_&lt; 1 Year</th>\n",
       "      <th>Vehicle_Age_&gt; 2 Years</th>\n",
       "      <th>Vehicle_Damage_Yes</th>\n",
       "      <th>Driving_License_1</th>\n",
       "      <th>Previously_Insured_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.159421</td>\n",
       "      <td>2.101969</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.307563</td>\n",
       "      <td>1.726275</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.892697</td>\n",
       "      <td>0.459721</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.225886</td>\n",
       "      <td>-1.689622</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.159205</td>\n",
       "      <td>0.089975</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Response       Age  Annual_Premium  Gender_Male  Vehicle_Age_< 1 Year  \\\n",
       "0         0 -1.159421        2.101969         True                 False   \n",
       "1         1  0.307563        1.726275         True                 False   \n",
       "2         0 -0.892697        0.459721        False                  True   \n",
       "3         0 -0.225886       -1.689622        False                 False   \n",
       "4         0 -0.159205        0.089975        False                 False   \n",
       "\n",
       "   Vehicle_Age_> 2 Years  Vehicle_Damage_Yes  Driving_License_1  \\\n",
       "0                  False                True               True   \n",
       "1                   True                True               True   \n",
       "2                  False               False               True   \n",
       "3                  False                True               True   \n",
       "4                  False               False               True   \n",
       "\n",
       "   Previously_Insured_1  \n",
       "0                 False  \n",
       "1                 False  \n",
       "2                  True  \n",
       "3                 False  \n",
       "4                  True  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на признаки (X) и целевую переменную (y)\n",
    "X = data.drop('Response', axis=1)\n",
    "y = data['Response']\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки. Только для проверки PCA, потом надо заменить на кросс-валидацию\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X2 = testD.drop('Response', axis=1)\n",
    "#y2 = testD['Response']\n",
    "#X2.to_pickle('X_train_phy.pkl')\n",
    "#y2.to_pickle('y_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6\n",
    "# Создаем объект PCA с n компонентами\n",
    "pca = PCA(n_components=n)\n",
    "\n",
    "# Применяем PCA к данным\n",
    "pca_data = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nX_train = pca.fit_transform(X_train)\\n\\nknn_param_grid = {'n_neighbors': [3]}\\nknn_model = GridSearchCV(KNeighborsClassifier(), knn_param_grid, cv=5)\\nknn_model.fit(X_train, y_train)\\n\\nX_test = pca.fit_transform(X_test)\\ny_pred = knn_model.predict(X_test)\\n# Отчет классификации\\nprint(classification_report(y_test, y_pred))\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Просто смотрю как в целом обучать модель используя pca. Потом уберем\n",
    "# Не советую расскоментировать тк на 5миллионах данных считается очень долго, я на меньшем количестве проверяла и оно работает\n",
    "\n",
    "\"\"\"\n",
    "X_train = pca.fit_transform(X_train)\n",
    "\n",
    "knn_param_grid = {'n_neighbors': [3]}\n",
    "knn_model = GridSearchCV(KNeighborsClassifier(), knn_param_grid, cv=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "X_test = pca.fit_transform(X_test)\n",
    "y_pred = knn_model.predict(X_test)\n",
    "# Отчет классификации\n",
    "print(classification_report(y_test, y_pred))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'filename = \"scaler.pkl\"\\nwith open(filename, \\'wb\\') as file:\\n    pickle.dump(scaler, file)\\nprint(f\"scaler сохранена в файл: {filename}\")\\n\\nfilename = \"pca.pkl\"\\nwith open(filename, \\'wb\\') as file:\\n    pickle.dump(pca, file)\\nprint(f\"PCA сохранена в файл: {filename}\")'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Сохранение преобразования в файл\n",
    "'''filename = \"scaler.pkl\"\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(scaler, file)\n",
    "print(f\"scaler сохранена в файл: {filename}\")\n",
    "\n",
    "filename = \"pca.pkl\"\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(pca, file)\n",
    "print(f\"PCA сохранена в файл: {filename}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.head()\n",
    "#X.to_pickle('X_train_phy.pkl')\n",
    "#y.to_pickle('y_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pca.transform(X)\n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('X_train_pca.pkl', 'wb') as file:\n",
    "#    pickle.dump(X_train, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Decision Tree\n",
    "t_start = time.time()\n",
    "tree_param_grid = {'max_depth': [10, 15], 'min_samples_split': [20, 50]}\n",
    "tree_model = GridSearchCV(DecisionTreeClassifier(), tree_param_grid, scoring = 'f1', cv=5)\n",
    "tree_model.fit(X_train, y_train)\n",
    "t_finish = time.time()\n",
    "dt = t_finish - t_start\n",
    "dt2 = dt / 60.\n",
    "print(\"Decision Tree Best Params:\", tree_model.best_params_)\n",
    "print(\"Time: \",  dt, \" sec or \", dt2, \"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lab = tree_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01555679353453881\n"
     ]
    }
   ],
   "source": [
    "print(tree_model.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.021228627169638876\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y, y_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4381967    2753]\n",
      " [ 610436    4845]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y, y_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Random Forest\n",
    "#rf_param_grid = {'n_estimators': [10, 50, 100, 200], 'max_depth': [5, 10, 15], 'min_samples_split': [3, 5, 10]}\n",
    "#rf_model = GridSearchCV(RandomForestClassifier(random_state=42), rf_param_grid, cv=5)\n",
    "#rf_model.fit(X_train, y_train)\n",
    "#print(\"Random Forest Best Params:\", rf_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other variants -- \n",
    "# Naive Bayes: https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "# other ensembles : https://scikit-learn.org/stable/modules/ensemble.html\n",
    "# Мне кажется, лучше не пробовать boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель сохранена в файл: tree1_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Сохранение модели в файл\n",
    "model_filename = \"tree1_model.pkl\"\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(tree_model, file)\n",
    "print(f\"Модель сохранена в файл: {model_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False\n",
    "\n",
    "\n",
    "scoring : https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "\n",
    "‘balanced_accuracy’\n",
    "‘f1’ \n",
    "‘precision’ -- Нужно смотреть, но не знаю, как пользоваться. Он сказал, важнее 'recall', но потом значит, что нам нужно свой программировать. \n",
    "(‘roc_auc’ тоже существует.)\n",
    "\n",
    "n_jobs, pre_dispatch наверно полезно"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
